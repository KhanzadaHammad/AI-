{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "svm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XRvauDO8vXzW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import log,dot,e,shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "xdi6DbNEv2bl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#linear SVM\n",
        "class SVM:  #wx+b\n",
        "  #constructor:\n",
        "  #learning rate is for changing the weights\n",
        "  #lamda_parma is gradientdecent rate to change weights\n",
        "  def __init__(self,learning_rate=1e-3,lamda_parma=1e-2,n_iters=1000):\n",
        "    self.lr=learning_rate\n",
        "    self.lamda_parma=lamda_parma\n",
        "    self.n_iters=n_iters\n",
        "    self.w=None\n",
        "    self.b=None\n",
        "\n",
        "  \n",
        "  #init the weights=0 according to number of features\n",
        "  def init_weight_bias(self,x):\n",
        "    n_features=x.shape[1]\n",
        "    self.w=np.zeros(n_features)\n",
        "    self.b=0\n",
        "\n",
        "  def get_classification_map(self,y):\n",
        "    #if y is less tha equal to 0 than map it to -1 else map it to 1\n",
        "    return np.where(y<=0,-1,1) \n",
        "\n",
        "  def fit(self,x,y):\n",
        "    #calling the function to init the weights\n",
        "    self.init_weight_bias(x)\n",
        "    #store the y(output)\n",
        "    self.cls_map=self.get_classification_map(y)\n",
        "\n",
        "    for _ in range(self.n_iters):\n",
        "      for index, i in enumerate(x):\n",
        "        constrain=self.constraint(i,index)\n",
        "        dw,db=self.gradients(constrain,i,index)\n",
        "        self.update_weights(dw,db)\n",
        "\n",
        "  #check the constraints by apply formula wx + b\n",
        "  #it is the bool function\n",
        "  def constraint(self,x,idx): #idx is the current index of x\n",
        "   linear_model= np.dot(x,self.w)+self.b\n",
        "   return self.cls_map[idx]*linear_model>=1\n",
        "\n",
        "  def gradients(self,constrain,x,idx):\n",
        "     #check if data poitn are in correct place\n",
        "     if constrain: \n",
        "       dw=self.lamda_parma*self.w\n",
        "       db=0\n",
        "       return dw,db\n",
        "\n",
        "      #if data point are wrong\n",
        "     dw=self.lamda_parma*self.w - np.dot(self.cls_map[idx],x)\n",
        "     db=-self.cls_map[idx]\n",
        "     return dw,db      \n",
        "  \n",
        "  def update_weights(self,dw,db):\n",
        "    self.w -=self.lr*dw\n",
        "    self.b -=self.lr*db\n",
        "\n",
        "  def predict(self,x):\n",
        "    estimate=np.dot(x,self.w.T)+self.b #wx+b\n",
        "    #compute the sign\n",
        "    prediction=np.sign(estimate) #if n<0 than it return -1 and 1 if n>0\n",
        "    #map class from {-1,1} to orignal values {0,1}\n",
        "    return np.where(prediction==-1,0,1)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "Aj4bDtB3v3zu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y=make_blobs( n_samples=250, n_features=2, centers=2, cluster_std=1.05, random_state=1)\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.1,shuffle=True,random_state=42)\n",
        "\n",
        "clf=SVM()\n",
        "clf.fit(x_train,y_train)\n",
        "prediction=clf.predict(x_test)\n",
        "\n",
        "def accuracy(y_true,y_pred):\n",
        "  accuracy=np.sum(y_true==y_pred)/len(y_true)\n",
        "  return accuracy\n",
        "\n",
        "print(\"SVM Accuracy: \",accuracy(y_test,prediction))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idRZKnNYEXyP",
        "outputId": "89bcf87a-84a3-4923-ab36-c400a7f374d4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3qtD77OHciV",
        "outputId": "95d5b914-c600-4019-929b-231e8ab78bd1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMot7DfMInue",
        "outputId": "cf0a99b0-6f10-4e6f-d3ad-0e0a57601333"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcypPhSzIsyj",
        "outputId": "b940c846-433b-42cc-869f-6d3b1ff3dc9d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHws5ao2IwQz",
        "outputId": "3cdf6e49-5c66-447a-dfda-811bac80aefc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25,)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OwJ65G4XIxrZ"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}