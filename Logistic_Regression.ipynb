{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "io9pLuw6tz1w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import log,dot,e,shape\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "LKjZalapu0Ra"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y=make_classification(n_features=4,n_classes=2)"
      ],
      "metadata": {
        "id": "-8f7yOE_ww4Z"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TuYZuRVxAuf",
        "outputId": "d02ba627-7fb9-4a99-e03f-1a844aa51e4b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.1)"
      ],
      "metadata": {
        "id": "L8RZZKtExQg1"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRp6GSKeyNx1",
        "outputId": "0f422873-9935-4ca7-e525-8a4c80577d46"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#standardizattion:\n",
        "def standardize(x_train):\n",
        "  for i in range(np.shape(x_train)[1]): #because data is 2 demensional so we have to add [1].\n",
        "    x_train[:,i]=(x_train[:,i]-np.mean(x_train[:,i])) / np.std(x_train[:,i])"
      ],
      "metadata": {
        "id": "RViEkDlVyTzt"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w=np.zeros((np.shape(X)[1]+1,1))\n",
        "print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phno-br60JSJ",
        "outputId": "694cb219-348f-410c-cbd6-119485b17329"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(X)[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcEuIfti5ICr",
        "outputId": "dfee7ca6-d7e6-4431-c02d-a74c39e1c9cf"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_x=np.c_[np.ones((np.shape(X)[0],1)),X]\n",
        "print(temp_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo0SeVIa3Ui_",
        "outputId": "1da23d50-1ff3-4475-e85e-05c4cee16f0d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.          0.95399145  1.12901607 -0.48828223  0.99293465]\n",
            " [ 1.         -1.11694139 -1.73963894  1.17730081  0.56999654]\n",
            " [ 1.         -1.07113362 -1.19160135  0.43799831 -1.43023359]\n",
            " [ 1.          0.25793033  0.56174934 -0.50383934 -0.79524308]\n",
            " [ 1.         -0.3505425  -0.2467888  -0.06421267 -1.06182696]\n",
            " [ 1.          0.7004756   0.7524453  -0.2475665   1.0464977 ]\n",
            " [ 1.          0.16180519  0.4029223  -0.38931086 -0.70840128]\n",
            " [ 1.          1.21696828  2.23736304 -1.77840256 -2.03904292]\n",
            " [ 1.         -0.81678341 -1.41745977  1.07157679  1.01945612]\n",
            " [ 1.          0.55870263  0.48118217 -0.02499709  1.32807037]\n",
            " [ 1.         -0.03155714  0.00536104 -0.04575795 -0.20995582]\n",
            " [ 1.         -0.96667871 -1.13264673  0.47827316 -1.0533507 ]\n",
            " [ 1.          0.40077393  0.53727505 -0.29641484  0.15598386]\n",
            " [ 1.          1.67035313  2.23607567 -1.23077997  0.66333895]\n",
            " [ 1.         -1.14539799 -1.7396115   1.14300675  0.40060344]\n",
            " [ 1.          0.78971731  1.73175492 -1.55976396 -2.48385388]\n",
            " [ 1.         -0.42018067 -0.84624572  0.72094246  1.0098809 ]\n",
            " [ 1.         -0.08954525 -0.488486    0.60032722  1.49308769]\n",
            " [ 1.          0.63625555  0.65637579 -0.18560688  1.06287566]\n",
            " [ 1.          0.80846175  1.54606629 -1.2680237  -1.60229356]\n",
            " [ 1.         -0.74819128 -1.04777298  0.61824052 -0.10561167]\n",
            " [ 1.          1.30049197  2.78097126 -2.4658841  -3.79654422]\n",
            " [ 1.          1.54830545  2.03095332 -1.0803451   0.78796356]\n",
            " [ 1.         -0.60692697 -0.24319058 -0.37804833 -2.60189897]\n",
            " [ 1.          1.43808981  1.89539399 -1.01650708  0.69449368]\n",
            " [ 1.         -0.85953456 -1.16219504  0.65008026 -0.29344639]\n",
            " [ 1.         -0.37271351 -0.58131039  0.39402648  0.19355442]\n",
            " [ 1.          0.07974244 -0.23057302  0.43023088  1.43055484]\n",
            " [ 1.         -0.45977699 -0.92635288  0.78940335  1.1065414 ]\n",
            " [ 1.          1.35485603  1.78608286 -0.95823977  0.65267826]\n",
            " [ 1.          0.62497992  1.30555243 -1.14023539 -1.69635174]\n",
            " [ 1.         -0.71120947 -0.896492    0.44345788 -0.5129847 ]\n",
            " [ 1.          0.24026058  0.62669732 -0.61925858 -1.16969577]\n",
            " [ 1.         -0.59009209 -1.09322038  0.87443165  1.02334193]\n",
            " [ 1.         -0.45309559 -0.92625142  0.79729893  1.14586618]\n",
            " [ 1.         -0.3263799  -0.09809745 -0.25067232 -1.53471816]\n",
            " [ 1.          0.77396194  1.3628659  -1.04398256 -1.04778529]\n",
            " [ 1.         -0.18269764 -0.61931265  0.67784434  1.48149507]\n",
            " [ 1.          1.56400859  2.04713577 -1.08490095  0.81426754]\n",
            " [ 1.          0.34845192  0.52281293 -0.33843232 -0.09528846]\n",
            " [ 1.         -0.89754471 -0.85469332  0.15856718 -1.79477433]\n",
            " [ 1.         -1.27029096 -1.47685905  0.61177872 -1.43198654]\n",
            " [ 1.          0.82699125  0.9447355  -0.37402145  1.00166687]\n",
            " [ 1.         -0.14152686 -0.56101714  0.64289717  1.48465407]\n",
            " [ 1.         -1.00563239 -1.14162334  0.44439579 -1.24784753]\n",
            " [ 1.         -0.29160268 -0.60386622  0.52435988  0.76959669]\n",
            " [ 1.         -0.28363526 -0.67920171  0.64315796  1.12941057]\n",
            " [ 1.          0.2962814   0.75363583 -0.73583607 -1.36286287]\n",
            " [ 1.         -1.43009001 -1.87690901  0.99934067 -0.72356301]\n",
            " [ 1.         -0.94243398 -1.23052842  0.64934814 -0.50320852]\n",
            " [ 1.         -0.38522297 -0.80223318  0.69922117  1.03531213]\n",
            " [ 1.          1.73008489  2.33656583 -1.30455056  0.60192898]\n",
            " [ 1.         -0.58117619 -1.0438284   0.81356474  0.87154996]\n",
            " [ 1.         -0.21832826 -0.24973079  0.09920334 -0.26312572]\n",
            " [ 1.         -0.48689371 -0.93435769  0.76836582  0.97842876]\n",
            " [ 1.          1.12326867  1.41312537 -0.69636573  0.82170268]\n",
            " [ 1.          0.39371215  0.25811915  0.09975296  1.27164229]\n",
            " [ 1.         -0.91927409 -1.46802993  1.02151211  0.6194872 ]\n",
            " [ 1.          0.1850413  -0.05078188  0.29635531  1.31134593]\n",
            " [ 1.          0.20589746  0.43148391 -0.37763864 -0.56455602]\n",
            " [ 1.         -0.85312172 -0.92072485  0.30776104 -1.25668156]\n",
            " [ 1.         -0.37454798 -0.64379018  0.48238984  0.44174701]\n",
            " [ 1.          0.25012822  0.0467252   0.23335524  1.29416306]\n",
            " [ 1.          0.95336353  1.70096741 -1.31814682 -1.38269761]\n",
            " [ 1.         -0.65354286 -1.12027303  0.83726948  0.75808144]\n",
            " [ 1.          1.10616892  2.04242728 -1.62919428 -1.8897496 ]\n",
            " [ 1.          1.56059443  2.07644449 -1.13149703  0.67241376]\n",
            " [ 1.         -1.17008537 -1.82519204  1.23734839  0.60865076]\n",
            " [ 1.          0.96360645  1.14495834 -0.49981844  0.98401823]\n",
            " [ 1.         -0.14857358 -0.58549939  0.66990457  1.54426383]\n",
            " [ 1.          0.90922355  1.72194744 -1.40169274 -1.73227719]\n",
            " [ 1.         -1.51623907 -2.25431803  1.44273724  0.3290884 ]\n",
            " [ 1.         -0.57610733 -1.08331633  0.87690858  1.06546047]\n",
            " [ 1.         -1.44146815 -2.12571928  1.34632325  0.24057463]\n",
            " [ 1.          0.69096386  0.73193471 -0.2292837   1.07497334]\n",
            " [ 1.         -0.7070312  -1.00387125  0.60414589 -0.04282499]\n",
            " [ 1.         -1.11562763 -1.66776409  1.07469143  0.27974481]\n",
            " [ 1.          0.42961112  0.8340617  -0.69192855 -0.90325471]\n",
            " [ 1.         -0.58580071 -1.00868273  0.75705039  0.69829023]\n",
            " [ 1.          0.55980911  1.02793346 -0.81624357 -0.93273923]\n",
            " [ 1.         -0.42275316 -0.82583868  0.68826354  0.90994954]\n",
            " [ 1.         -0.81096475 -1.35224355  0.98404256  0.7836161 ]\n",
            " [ 1.         -0.21292054 -0.63802434  0.66858863  1.37930649]\n",
            " [ 1.          1.59512545  2.10924608 -1.13748038  0.74179889]\n",
            " [ 1.          0.0499945  -0.03056497  0.10448768  0.42415522]\n",
            " [ 1.          1.19917073  1.55696833 -0.81351636  0.67669955]\n",
            " [ 1.          0.1121683   0.30232544 -0.30323403 -0.58649768]\n",
            " [ 1.         -0.73129622 -1.19916314  0.85803506  0.62271062]\n",
            " [ 1.         -0.81285308 -1.40909405  1.0641808   1.00814351]\n",
            " [ 1.          1.89799571  2.61696625 -1.50890239  0.43794957]\n",
            " [ 1.         -1.0287664  -1.31455748  0.66723626 -0.66830215]\n",
            " [ 1.          0.50044952  0.95970947 -0.78879848 -1.00292404]\n",
            " [ 1.         -0.64120863 -0.87857735  0.50175118 -0.17086442]\n",
            " [ 1.         -0.63308236 -1.13421407  0.88210769  0.93760835]\n",
            " [ 1.         -1.01849798 -1.11340574  0.38800436 -1.44139999]\n",
            " [ 1.         -0.85582645 -0.56388862 -0.21276958 -2.7525802 ]\n",
            " [ 1.          1.10354396  1.8644983  -1.37442569 -1.1674886 ]\n",
            " [ 1.         -0.67682694 -0.77156277  0.30374623 -0.82653869]\n",
            " [ 1.          0.56645579  0.8654232  -0.57266554 -0.219266  ]\n",
            " [ 1.         -1.82783034 -2.62859687  1.610223    0.02767449]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LogidticRegression:\n",
        "#initialize:\n",
        "  def initialize(self,X):\n",
        "    weights=np.zeros((np.shape(X)[1]+1,1)) # feature vectors\n",
        "    X = np.c_[np.ones((np.shape(X)[0],1)),X]  #add a bias column of ones to our feature vectors matrix\n",
        "    return weights,X\n",
        "#sigmoid:\n",
        "  def sigmoid(self,z):\n",
        "    sig=1/(1+np.e**(-z))\n",
        "    return sig\n",
        "#Gradient Descent:\n",
        "  def fit(self,X,y,alpha=0.001,iter=100):\n",
        "    weights,X = self.initialize(X)\n",
        "#cost function:\n",
        "    def cost(theta):\n",
        "      z=dot(X,theta)\n",
        "      cost0=y.T.dot(log(self.sigmoid(z)))\n",
        "      cost1=(1-y).T.dot(log(1-self.sigmoid(z)))\n",
        "      cost=-((cost1+cost0))/len(y)\n",
        "      return cost\n",
        "    cost_list = np.zeros(iter,)\n",
        "    for i in range(iter):\n",
        "      weights = weights - alpha * dot(X.T, self.sigmoid(dot(X,weights)) - np.reshape(y,(len(y),1)))\n",
        "      cost_list[i] = cost(weights)\n",
        "    self.weights = weights\n",
        "    return cost_list\n",
        "#predict:\n",
        "  def predict(self,X):\n",
        "    z=dot(self.initialize(X)[1],self.weights)\n",
        "    lis=[]\n",
        "    for i in self.sigmoid(z):\n",
        "      if i>0.5:\n",
        "        lis.append(1)\n",
        "      else:\n",
        "        lis.append(0)\n",
        "    return lis"
      ],
      "metadata": {
        "id": "Jfo4g-nE6LCZ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#f1score:\n",
        "def f1_score(y,y_hat):\n",
        "  tp,tn,fp,fn=0,0,0,0\n",
        "  for i in range(len(y)):\n",
        "    if y[i]==1 and y_hat[i]==1:\n",
        "     tp=tp+1\n",
        "    elif y[i]==1 and y_hat[i]==0:\n",
        "     fn=fn+1\n",
        "    elif y[i]==0 and y_hat[i]==1:\n",
        "     fp=fp+1\n",
        "    elif y[i]==0 and y_hat[i]==0:\n",
        "     tn=tn+1 \n",
        "  precision=tp/(tp+fp)\n",
        "  recall=tp/(tp+fn)\n",
        "  f1_score=2*precision*recall/(precision+recall)\n",
        "  return f1_score"
      ],
      "metadata": {
        "id": "4ZT8njBIGzBw"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling:\n",
        "standardize(x_train)\n",
        "standardize(x_test)\n",
        "obj1=LogidticRegression()\n",
        "model=obj1.fit(x_train,y_train)\n",
        "y_predict=obj1.predict(x_test)\n",
        "y_tr=obj1.predict(x_train)\n",
        "\n",
        "f1_score_traing=f1_score(y_train,y_tr)\n",
        "f1_score_test=f1_score(y_test,y_predict)\n",
        "print(\"F1 Score of Training:\",f1_score_traing)\n",
        "print(\"F1 Score of Testing:\",f1_score_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jtu3hWlLzr2",
        "outputId": "ec11ae44-020e-4c4b-d476-d09f07b59fe1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score of Training: 0.9278350515463919\n",
            "F1 Score of Testing: 0.888888888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "model=LogisticRegression().fit(x_train,y_train)\n",
        "y_pre=model.predict(x_test)\n",
        "y_tr=model.predict(x_train)\n",
        "\n",
        "print(\"F1 Score of Training:\",f1_score(y_train,y_tr))\n",
        "print(\"F1 Score of Testing:\",f1_score(y_test,y_pre))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ5jXJKFQ5am",
        "outputId": "97b0475d-13e2-4a5d-e498-b555f43b369b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score of Training: 0.9361702127659574\n",
            "F1 Score of Testing: 0.888888888888889\n"
          ]
        }
      ]
    }
  ]
}